# Kafka 기반 안전한 대용량 데이터 처리 시스템

이 프로젝트는 Apache Kafka를 활용하여 **대용량 데이터의 비동기 처리**, **서비스 장애 시 자동 복구**, 그리고 **실시간 스트리밍 처리 안정성**을 목표로 구현된 백엔드 아키텍처입니다.

## ✅ 주요 목적

* **대량의 사용자 요청을 안전하게 수신하고 손실 없이 처리**
* **Kafka를 통한 비동기 이벤트 큐 처리 구조 학습**
* **Redis를 통한 응답 속도 개선 및 캐시 활용**
* **JMeter를 이용한 성능 테스트 및 병목 구간 분석**
* **장애 발생 시 Kafka 로그를 통한 복구 흐름 체험**

이 시스템은 Kafka의 메시지 지속성, 소비자 오프셋 제어, 장애 복구 능력을 직접 실험하며,
실제 대규모 서비스 환경에서 활용할 수 있는 이벤트 기반 구조를 체험할 수 있도록 구성되어 있습니다.

---

## 🧱 기술 스택

* Java 17
* Spring Boot 3.x
* Apache Kafka
* Redis
* Docker & Docker Compose
* JMeter (성능 테스트)
* Kafka UI / Redis Insight (관리 도구)

---

## 💡 시스템 흐름 예시 (음식 주문 서비스)

1. 사용자 주문 요청 발생 → `producer-service`에서 Kafka에 메시지 전송
2. Kafka가 해당 메시지를 저장 및 큐잉
3. `consumer-service`에서 메시지를 순차 소비하여 주문 처리
4. 처리 결과를 Redis에 저장하여 빠른 조회 가능
5. 장애 발생 시 Kafka 로그에서 재처리 가능

---

## 📊 성능 테스트

* JMeter를 통해 TPS(초당 처리량), 처리 지연시간 분석
* 장애 발생 후 복구 시 처리 시간 비교
* Redis 캐시 여부에 따른 응답 속도 비교

---

## 🔄 복구 시나리오 예시

1. `consumer-service` 중지
2. Kafka는 메시지를 계속 저장 (offset 기록)
3. 서비스 복구 후, Kafka 로그를 기반으로 재처리
4. 메시지 손실 없이 안정적 처리 확인

---

Pull Request와 Issue는 언제든 환영입니다 😊
